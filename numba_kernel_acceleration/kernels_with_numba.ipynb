{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9901665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import *\n",
    "from numba import jit, guvectorize\n",
    "from numba import cuda, float32\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.spatial.distance as spd\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d401230",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_1k = np.random.rand(1024, 1024)\n",
    "ex_2k = np.random.rand(2048, 2048)\n",
    "ex_4k = np.random.rand(4096, 4096)\n",
    "ex_10k = np.random.rand(10240, 10240)\n",
    "# ex_20k = np.random.rand(20480, 20480)\n",
    "# ex_40k = np.random.rand(40960, 40960)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13a8392",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_16 = np.random.rand(16, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5261f54d",
   "metadata": {},
   "source": [
    "# Linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b301a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_linear_kernel(X, Y):\n",
    "    return X @ Y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30641fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "np_linear_kernel(ex_10k, ex_10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66707b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True, parallel=True)\n",
    "def jit_linear_kernel(X, Y):\n",
    "    return X @ Y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6b773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "jit_linear_kernel(ex_4k, ex_4k.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c084fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jit(\"float32(f4[:,:], f4[:,:])\")\n",
    "# def jit_linear_kernel(x, y):\n",
    "#     c = np.empty([x.shape[0], y.shape[1]])\n",
    "#     for i in range(x.shape[0]):\n",
    "#         for j in range(y.shape[1]):\n",
    "#             for k in range(x.shape[1]):\n",
    "#                 c[i, j] += x[i, k] * y[k, j]\n",
    "#     return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc647fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jit(\"void(float32[:,:],float32[:,:],float32[:,:])\")\n",
    "# def jit_linear_kernel(x, y, c):\n",
    "#     for i in range(x.shape[0]):\n",
    "#         for j in range(y.shape[1]):\n",
    "#             for k in range(x.shape[1]):\n",
    "#                 c[i, j] += x[i, k] * y[k, j]\n",
    "#     return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c92ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.select_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa39c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = cuda.get_current_device()\n",
    "gpu.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70bfd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "TPB = 32\n",
    "\n",
    "# source: https://stackoverflow.com/questions/64197780/how-to-generalize-fast-matrix-multiplication-on-gpu-using-numba\n",
    "@cuda.jit\n",
    "def cuda_linear_kernel(A, B, C):\n",
    "    \n",
    "    # Define an array in the shared memory\n",
    "    # The size and type of the arrays must be known at compile time\n",
    "    sA = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "    sB = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "\n",
    "    x, y = cuda.grid(2)\n",
    "\n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    bpg = cuda.gridDim.x    # blocks per grid\n",
    "\n",
    "    # Each thread computes one element in the result matrix.\n",
    "    # The dot product is chunked into dot products of TPB-long vectors.\n",
    "    tmp = float32(0.)\n",
    "    \n",
    "    for i in range(bpg):\n",
    "        # Preload data into shared memory\n",
    "        sA[tx, ty] = 0\n",
    "        sB[tx, ty] = 0\n",
    "        \n",
    "        # Verifying that all shapes are properly respected for matrix A and B\n",
    "        if x < A.shape[0] and (ty + i * TPB) < A.shape[1]:\n",
    "#             sA[tx, ty] = A[x, ty + i * TPB]\n",
    "            sA[ty, tx] = A[x, ty + i * TPB]\n",
    "            \n",
    "        if y < B.shape[1] and (tx +i * TPB) < B.shape[0]:\n",
    "#             sB[tx, ty] = B[tx + i * TPB, y]\n",
    "            sB[ty, tx] = B[tx + i * TPB, y]\n",
    "\n",
    "        # Wait until all threads finish preloading\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        # Computes partial product on the shared memory\n",
    "        for j in range(TPB):\n",
    "#             tmp += sA[tx, j] * sB[j, ty]\n",
    "            tmp += sA[ty, j] * sB[j, tx]\n",
    "            \n",
    "\n",
    "        # Wait until all threads finish computing\n",
    "        cuda.syncthreads()\n",
    "        \n",
    "    if x < C.shape[0] and y < C.shape[1]:\n",
    "        C[x, y] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e9a3ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_linear_np = []\n",
    "time_linear_jit = []\n",
    "time_linear_cuda = []\n",
    "\n",
    "for arr in [ex_1k, ex_2k, ex_4k, ex_10k]:\n",
    "    \n",
    "    start = timer()\n",
    "    test = np_linear_kernel(arr, arr)\n",
    "    end_np = timer() - start\n",
    "    time_linear_np.append(end_np)\n",
    "    \n",
    "    # jit version\n",
    "    c = np.empty([arr.shape[0], arr.shape[1]])\n",
    "    start = timer()\n",
    "    test = jit_linear_kernel(arr, arr.T)\n",
    "    end_py = timer() - start\n",
    "    time_linear_jit.append(end_py)\n",
    "    \n",
    "    # cuda version\n",
    "    x_h = arr\n",
    "    y_h = arr\n",
    "    z_h = np.zeros([arr.shape[0], arr.shape[1]])\n",
    "\n",
    "\n",
    "    x_d = cuda.to_device(x_h)\n",
    "    y_d = cuda.to_device(y_h)\n",
    "    z_d = cuda.to_device(z_h)\n",
    "\n",
    "    TPB = 32\n",
    "    threadsperblock = (TPB, TPB)\n",
    "    blockspergrid_x = math.ceil(z_h.shape[0] / threadsperblock[0])\n",
    "    blockspergrid_y = math.ceil(z_h.shape[1] / threadsperblock[1])\n",
    "    blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
    "    \n",
    "    start = timer()\n",
    "    test = cuda_linear_kernel[blockspergrid, threadsperblock](x_d, y_d, z_d)\n",
    "#     z_h = z_d.copy_to_host()\n",
    "    end_cuda = timer() - start\n",
    "    time_linear_cuda.append(end_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6d5f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b671cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3f9b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_arr = [\"1024\", \"2048\", \"4096\", \"10240\"]\n",
    "linear_df = pd.DataFrame({\"numpy\": time_linear_np, \"jit\": time_linear_jit, \"cuda\": time_linear_cuda}, \n",
    "                         index=size_arr)\n",
    "linear_df.plot.bar(rot=0)\n",
    "plt.title(\"linear kernel perf. based on matrix size\")\n",
    "plt.xlabel(\"matrix size\")\n",
    "plt.ylabel(\"time (s)\");\n",
    "plt.savefig(\"linear_performance.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f77fed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting results pandas data frame\n",
    "# linear_df.to_csv(\"./linear_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd1ab1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_up_linear_df = linear_df.apply(lambda x: linear_df['numpy'] / x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2dd210",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_up_linear_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1633491",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_up_linear_df.plot.bar(rot=0)\n",
    "plt.title(\"speedup vs numpy version for linear kernel\")\n",
    "plt.xlabel(\"matrix size\")\n",
    "plt.ylabel(\"speedup\");\n",
    "plt.savefig(\"linear_speedup.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b31105",
   "metadata": {},
   "source": [
    "# Polynomial kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec702213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_polynomial_kernel(X, Y, c, r):\n",
    "    \"\"\"Numpy version of the polynomial kernel\"\"\"\n",
    "    return (X @ Y.T + c) ** r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353694fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "np_polynomial_kernel(ex_10k, ex_10k, 2., 2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4877770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True, parallel=True)\n",
    "def np_jit_polynomial_kernel(X, Y, c, r):\n",
    "    \"\"\"Numpy version of the polynomial kernel\"\"\"\n",
    "    return (X @ Y.T + c) ** r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5b6965",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "np_jit_polynomial_kernel(ex_10k, ex_10k, 2., 2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89598d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(\"void(float32[:,:], float32[:,:], float32[:,:])\")\n",
    "def jit_polynomial_kernel(X, Y, C):\n",
    "    \"\"\"Just in time version of the polynomial kernel\"\"\"\n",
    "#     C = np.zeros([X.shape[0], Y.shape[1]])\n",
    "    for i in range(X.shape[0]): \n",
    "        for j in range(Y.shape[1]):      \n",
    "            for k in range(X.shape[1]):\n",
    "                C[i, j] += (X[i, k] * Y[k, j])\n",
    "                \n",
    "    C = (C + 2.)**2.\n",
    "    \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f012089d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "C = np.zeros([ex_1k.shape[0], ex_1k.shape[1]])\n",
    "jit_polynomial_kernel(ex_1k, ex_1k, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41aa9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TPB = 32\n",
    "\n",
    "@cuda.jit\n",
    "def cuda_polynomial_kernel(A, B, C, c=2., r=2.):\n",
    "    \"\"\"Cuda version of the polynomial kernel\"\"\"\n",
    "\n",
    "    sA = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "    sB = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "\n",
    "    x, y = cuda.grid(2)\n",
    "\n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    bpg = cuda.gridDim.x    # blocks per grid\n",
    "\n",
    "    tmp = float32(0.)\n",
    "    \n",
    "    for i in range(bpg):\n",
    "        \n",
    "        sA[tx, ty] = 0\n",
    "        sB[tx, ty] = 0\n",
    "        \n",
    "        if x < A.shape[0] and (ty + i * TPB) < A.shape[1]:\n",
    "            sA[tx, ty] = A[x, ty + i * TPB]\n",
    "            \n",
    "        if y < B.shape[1] and (tx + i * TPB) < B.shape[0]:\n",
    "            sB[tx, ty] = B[tx + i * TPB, y]\n",
    "\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        # Computes partial product on the shared memory\n",
    "        for j in range(TPB):\n",
    "            tmp += (sA[tx, j] * sB[j, ty])\n",
    "\n",
    "        cuda.syncthreads()\n",
    "        \n",
    "    if x < C.shape[0] and y < C.shape[1]:\n",
    "        C[x, y] = (tmp + c)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ffbfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda version\n",
    "x_h = ex_1k\n",
    "y_h = ex_1k\n",
    "z_h = np.zeros_like(ex_1k)\n",
    "\n",
    "\n",
    "x_d = cuda.to_device(x_h)\n",
    "y_d = cuda.to_device(y_h)\n",
    "z_d = cuda.to_device(z_h)\n",
    "\n",
    "TPB = 32\n",
    "threadsperblock = (TPB, TPB)\n",
    "blockspergrid_x = math.ceil(z_h.shape[0] / threadsperblock[0])\n",
    "blockspergrid_y = math.ceil(z_h.shape[1] / threadsperblock[1])\n",
    "blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
    "\n",
    "start = timer()\n",
    "test = cuda_polynomial_kernel[blockspergrid, threadsperblock](x_d, y_d, z_d, 2., 2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e46d282",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_h = z_d.copy_to_host()\n",
    "z_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2a57d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_poly_np = []\n",
    "time_poly_jit = []\n",
    "time_poly_cuda = []\n",
    "\n",
    "for arr in [ex_1k, ex_2k, ex_4k, ex_10k]:\n",
    "    \n",
    "    start = timer()\n",
    "    test = np_polynomial_kernel(arr, arr, 2., 2.)\n",
    "    end_np = timer() - start\n",
    "    time_poly_np.append(end_np)\n",
    "    \n",
    "    # jit version\n",
    "    C = np.zeros([arr.shape[0], arr.shape[1]])\n",
    "    start = timer()\n",
    "    test = np_jit_polynomial_kernel(arr, arr, 2., 2.)\n",
    "    end_py = timer() - start\n",
    "    time_poly_jit.append(end_py)\n",
    "    \n",
    "    # cuda version\n",
    "    x_h = arr\n",
    "    y_h = arr\n",
    "    z_h = np.zeros([arr.shape[0], arr.shape[1]])\n",
    "\n",
    "\n",
    "    x_d = cuda.to_device(x_h)\n",
    "    y_d = cuda.to_device(y_h)\n",
    "    z_d = cuda.to_device(z_h)\n",
    "\n",
    "    TPB = 32\n",
    "    threadsperblock = (TPB, TPB)\n",
    "    blockspergrid_x = math.ceil(z_h.shape[0] / threadsperblock[0])\n",
    "    blockspergrid_y = math.ceil(z_h.shape[1] / threadsperblock[1])\n",
    "    blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
    "    \n",
    "    start = timer()\n",
    "    test = cuda_polynomial_kernel[blockspergrid, threadsperblock](x_d, y_d, z_d, 2., 2.)\n",
    "#     z_h = z_d.copy_to_host()\n",
    "    end_cuda = timer() - start\n",
    "    time_poly_cuda.append(end_cuda)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba8685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_arr = [\"1024\", \"2048\", \"4096\", \"10240\"]\n",
    "poly_df = pd.DataFrame({\"numpy\": time_poly_np, \"jit\": time_poly_jit, \"cuda\": time_poly_cuda}, \n",
    "                         index=size_arr)\n",
    "poly_df.plot.bar(rot=0)\n",
    "plt.title(\"polynomial kernel perf. based on matrix size\")\n",
    "plt.xlabel(\"matrix size\")\n",
    "plt.ylabel(\"time (s)\");\n",
    "plt.savefig(\"polynomial_performance.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d31dc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_up_poly_df = poly_df.apply(lambda x: poly_df['numpy'] / x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5c68aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting results pandas data frame\n",
    "poly_df.to_csv(\"./poly_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483d7b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_up_poly_df.plot.bar(rot=0)\n",
    "plt.title(\"speedup vs numpy version for polynomial kernel\")\n",
    "plt.xlabel(\"matrix size\")\n",
    "plt.ylabel(\"speedup\");\n",
    "plt.savefig(\"polynomial_speedup.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eb1e24",
   "metadata": {},
   "source": [
    "# Gaussian kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7aac05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_gaussian_kernel(X, Y, sigma = 1.):\n",
    "    \"\"\"Numpy (and scipy) version of the gaussian kernel\"\"\"\n",
    "    # same matrices\n",
    "    if np.array_equal(X, Y) and X.ndim > 1:\n",
    "        return np.exp( - spd.squareform(spd.pdist(X, 'euclidean'))**2 / (2*sigma**2) )\n",
    "\n",
    "    elif not np.array_equal(X, Y) and X.shape[0] != Y.shape[0] and X.shape[1] == Y.shape[1]: # two matrices of different sizes\n",
    "        return np.exp( - spd.cdist(X, Y, 'euclidean')**2/ (2*sigma**2))\n",
    "\n",
    "    elif not np.array_equal(X, Y) and X.ndim == Y.ndim == 1: # vectors\n",
    "        return np.exp(- np.linalg.norm(X - Y)**2 / (2*sigma**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dc6353",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "np_gaussian_kernel(ex_10k, ex_10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c490ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def jit_gaussian_kernel(X, Y, sigma=1.):\n",
    "    C = np.empty([X.shape[0], Y.shape[1]])\n",
    "    for i in range(X.shape[0]):\n",
    "        C[i, :] = (X[i,:] - Y[:, i])**2\n",
    "        C[i, :] = np.exp(-C[i, :] / (2*sigma**2))\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c3f7d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "jit_gaussian_kernel(ex_10k, ex_10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8a21ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "TPB = 32\n",
    "\n",
    "@cuda.jit\n",
    "def cuda_gaussian_kernel(A, B, C, sigma=1.):\n",
    "    \n",
    "    # Define an array in the shared memory\n",
    "    # The size and type of the arrays must be known at compile time\n",
    "    sA = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "    sB = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "\n",
    "    x, y = cuda.grid(2)\n",
    "\n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    \n",
    "    bpg = cuda.gridDim.x    # blocks per grid\n",
    "\n",
    "    tmp = float32(0.)\n",
    "    for i in range(bpg):\n",
    "        \n",
    "        sA[tx, ty] = 0\n",
    "        sB[tx, ty] = 0\n",
    "        \n",
    "        if x < A.shape[0] and (ty + i * TPB) < A.shape[1]:\n",
    "            sA[tx, ty] = A[x, ty + i * TPB]\n",
    "            \n",
    "        if y < B.shape[1] and (tx+i*TPB) < B.shape[0]:\n",
    "            sB[tx, ty] = B[tx + i * TPB, y]\n",
    "\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        # Computes partial product on the shared memory\n",
    "        for j in range(TPB):\n",
    "            tmp += (sA[tx, j] - sB[j, ty])**2\n",
    "#             tmp = math.exp(-tmp / 2 * sigma**2)\n",
    "#             tmp += math.exp(-((sA[tx, j] - sB[j, ty])**2)/2*sigma**2) \n",
    "\n",
    "        cuda.syncthreads()\n",
    "        \n",
    "        tmp = math.exp(-tmp / (2 * sigma**2))\n",
    "        \n",
    "    if x < C.shape[0] and y < C.shape[1]:\n",
    "        C[x, y] = tmp\n",
    "#         C[x, y] = math.exp(-C[x, y] / (2 * sigma**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612ebd03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_np = []\n",
    "time_jit = []\n",
    "time_cuda = []\n",
    "\n",
    "for arr in [ex_1k, ex_2k, ex_4k, ex_10k]:\n",
    "    \n",
    "    start = timer()\n",
    "    test = np_gaussian_kernel(arr, arr)\n",
    "    end_np = timer() - start\n",
    "    time_np.append(end_np)\n",
    "    \n",
    "    # jit version\n",
    "    start = timer()\n",
    "    test = jit_gaussian_kernel(arr, arr)\n",
    "    end_py = timer() - start\n",
    "    time_jit.append(end_py)\n",
    "    \n",
    "    # cuda version\n",
    "    x_h = arr\n",
    "    y_h = arr\n",
    "    z_h = np.zeros([arr.shape[0], arr.shape[1]])\n",
    "\n",
    "\n",
    "    x_d = cuda.to_device(x_h)\n",
    "    y_d = cuda.to_device(y_h)\n",
    "    z_d = cuda.to_device(z_h)\n",
    "\n",
    "    TPB = 32\n",
    "    threadsperblock = (TPB, TPB)\n",
    "    blockspergrid_x = math.ceil(z_h.shape[0] / threadsperblock[0])\n",
    "    blockspergrid_y = math.ceil(z_h.shape[1] / threadsperblock[1])\n",
    "    blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
    "    \n",
    "    start = timer()\n",
    "    test = cuda_gaussian_kernel[blockspergrid, threadsperblock](x_d, y_d, z_d, 1.)\n",
    "    #z_h = z_d.copy_to_host()\n",
    "    end_cuda = timer() - start\n",
    "    time_cuda.append(end_cuda)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca29c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda version\n",
    "# x_h = ex_1k\n",
    "# y_h = ex_1k\n",
    "# z_h = np.zeros_like(ex_1k)\n",
    "\n",
    "\n",
    "# x_d = cuda.to_device(x_h)\n",
    "# y_d = cuda.to_device(y_h)\n",
    "# z_d = cuda.to_device(z_h)\n",
    "\n",
    "# TPB = 32\n",
    "# threadsperblock = (TPB, TPB)\n",
    "# blockspergrid_x = math.ceil(z_h.shape[0] / threadsperblock[0])\n",
    "# blockspergrid_y = math.ceil(z_h.shape[1] / threadsperblock[1])\n",
    "# blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
    "\n",
    "# start = timer()\n",
    "# test = cuda_gaussian_kernel[blockspergrid, threadsperblock](x_d, y_d, z_d, 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b619ade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z_h = z_d.copy_to_host()\n",
    "# z_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff86334",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_arr = [\"1024\", \"2048\", \"4096\", \"10240\"]\n",
    "gauss_df = pd.DataFrame({\"numpy\": time_np, \"jit\": time_jit, \"cuda\": time_cuda}, \n",
    "                         index=size_arr)\n",
    "gauss_df.plot.bar(rot=0)\n",
    "plt.title(\"Gaussian kernel perf. based on matrix size\")\n",
    "plt.xlabel(\"matrix size\")\n",
    "plt.ylabel(\"time (s)\");\n",
    "plt.savefig(\"gaussian_performance.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea866e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf300c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_up_gauss_df = gauss_df.apply(lambda x: gauss_df['numpy'] / x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274c88fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_up_gauss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4268977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting results pandas data frame\n",
    "gauss_df.to_csv(\"./gauss_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f82097",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_up_gauss_df[[\"numpy\", \"jit\"]].plot.bar(rot=0)\n",
    "plt.title(\"speedup of gaussian kernel compared to numpy version\")\n",
    "plt.xlabel(\"matrix size\")\n",
    "plt.ylabel(\"speedup\");\n",
    "plt.savefig(\"gaussian_speedup.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
